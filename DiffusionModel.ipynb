{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import logging\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "def load_data(data_dir):\n",
    "    all_data = []\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            df = pd.read_csv(file_path, skipinitialspace=False)\n",
    "            df = df[df[' Label'] != 'BENIGN']  #Removing rows with 'BENIGN' label and dropping label column\n",
    "            df = df.drop(' Label', axis=1)   \n",
    "            all_data.append(df)\n",
    "\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    logging.info(f\"Initial data shape: {combined_data.shape}\")\n",
    "\n",
    "    #replacing non-numeric values with NaN\n",
    "    for col in combined_data.columns:\n",
    "        combined_data[col] = pd.to_numeric(combined_data[col], errors='coerce')\n",
    "    \n",
    "    #replacing infinite values with Nan\n",
    "    combined_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    combined_data = combined_data.dropna()\n",
    "    logging.info(f\"Data shape after cleaning: {combined_data.shape}\")\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    column_names = data.columns\n",
    "    column_types = data.dtypes\n",
    "    \n",
    "    # Clip the data to handle extreme values (1st to 99th percentile)\n",
    "    data = data.clip(lower=data.quantile(0.01), upper=data.quantile(0.99), axis=1)\n",
    "    \n",
    "    #ensure outputs are non-negative\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(data)\n",
    "    \n",
    "    return scaled_features, scaler, column_names, column_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid()  #ensure output is in [0,1] to match MinMax scaling\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to prevent overfitting\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.0001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(inputs, noise_factor=0.05):\n",
    "    #Adds random noise to the inputs for data augmentation\n",
    "    noisy_inputs = inputs + noise_factor * torch.randn_like(inputs)\n",
    "    return torch.clamp(noisy_inputs, 0.0, 1.0)  #ensures still in [0, 1] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=50, device='cpu'):\n",
    "    criterion = nn.MSELoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5) \n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.0001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch_x = batch[0].to(device)  #load batch to device\n",
    "\n",
    "            #Adding noise\n",
    "            noisy_batch_x = add_noise(batch_x)\n",
    "\n",
    "            #forward pass\n",
    "            outputs = model(noisy_batch_x)\n",
    "            loss = criterion(outputs, batch_x)\n",
    "\n",
    "            #backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        #validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch_x = batch[0].to(device)\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_x)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        logging.info(f\"Epoch [{epoch+1}/{epochs}], Avg Train Loss: {avg_train_loss:.4f}, Avg Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "      \n",
    "        scheduler.step()\n",
    "\n",
    "        #check early stopping condition\n",
    "        early_stopping(avg_val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            logging.info(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    #saving model\n",
    "    torch.save(model.state_dict(), 'diffusion_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate new samples\n",
    "def generate_samples(model, scaler, column_names, column_types, num_samples=1000, device='cpu'):\n",
    "    model.eval() \n",
    "    input_dim = len(column_names)\n",
    "    with torch.no_grad():\n",
    "        samples = torch.randn(num_samples, input_dim).to(device)\n",
    "        generated_samples = model(samples).cpu().numpy()\n",
    "    \n",
    "    #reverse scaling using inverse transform\n",
    "    generated_samples = scaler.inverse_transform(generated_samples)\n",
    "    \n",
    "    #preserve column types\n",
    "    generated_df = pd.DataFrame(generated_samples, columns=column_names)\n",
    "    for col, col_type in zip(column_names, column_types):\n",
    "        generated_df[col] = generated_df[col].astype(col_type)\n",
    "    \n",
    "    return generated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initial data shape: (557646, 78)\n",
      "INFO:root:Data shape after cleaning: (556556, 78)\n",
      "/home/marif_umassd_edu/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/marif_umassd_edu/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "INFO:root:Epoch [1/50], Avg Train Loss: 0.0051, Avg Val Loss: 0.0006\n",
      "INFO:root:Epoch [2/50], Avg Train Loss: 0.0017, Avg Val Loss: 0.0005\n",
      "INFO:root:Epoch [3/50], Avg Train Loss: 0.0016, Avg Val Loss: 0.0006\n",
      "INFO:root:Epoch [4/50], Avg Train Loss: 0.0016, Avg Val Loss: 0.0005\n",
      "INFO:root:Epoch [5/50], Avg Train Loss: 0.0016, Avg Val Loss: 0.0005\n",
      "INFO:root:Epoch [6/50], Avg Train Loss: 0.0016, Avg Val Loss: 0.0005\n",
      "INFO:root:Epoch [7/50], Avg Train Loss: 0.0016, Avg Val Loss: 0.0005\n",
      "INFO:root:Epoch [8/50], Avg Train Loss: 0.0016, Avg Val Loss: 0.0005\n",
      "INFO:root:Epoch [9/50], Avg Train Loss: 0.0016, Avg Val Loss: 0.0005\n",
      "INFO:root:Epoch [10/50], Avg Train Loss: 0.0016, Avg Val Loss: 0.0006\n",
      "INFO:root:Epoch [11/50], Avg Train Loss: 0.0014, Avg Val Loss: 0.0004\n",
      "INFO:root:Epoch [12/50], Avg Train Loss: 0.0014, Avg Val Loss: 0.0004\n",
      "INFO:root:Early stopping triggered\n",
      "INFO:root:Generated data saved to diffusion_model_results.csv\n"
     ]
    }
   ],
   "source": [
    "def main(data_dir, output_file, epochs=50, batch_size=64, num_samples=1000):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    data = load_data(data_dir)\n",
    "    scaled_features, scaler, column_names, column_types = preprocess_data(data)\n",
    "\n",
    "    #split data into train and validation sets\n",
    "    dataset = TensorDataset(torch.tensor(scaled_features, dtype=torch.float32))\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    #Create DataLoader for batch processing\n",
    "    num_workers = min(4, multiprocessing.cpu_count() - 1)  # Use a safe number of workers\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    \n",
    "    input_dim = scaled_features.shape[1]\n",
    "    model = DiffusionModel(input_dim).to(device)\n",
    "    \n",
    "    train_model(model, train_loader, val_loader, epochs, device)\n",
    "\n",
    "    #generate samples and save them to a CSV file\n",
    "    generated_samples = generate_samples(model, scaler, column_names, column_types, num_samples, device)\n",
    "    generated_samples.to_csv(output_file, index=False)\n",
    "    logging.info(f\"Generated data saved to {output_file}\")\n",
    "\n",
    "#parameters\n",
    "data_dir = 'gan_dataset'  #directory containing all CSV files\n",
    "output_file = 'diffusion_model_results.csv'\n",
    "epochs = 50  \n",
    "batch_size = 64 \n",
    "num_samples = 1000  #Number of generated samples\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(data_dir, output_file, epochs, batch_size, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Statistic for Destination Port: 0.5722979304720521\n",
      "P-value for Destination Port: 7.4275823625489e-310\n",
      "\n",
      "KS Statistic for Flow Duration: 0.4238204534962466\n",
      "P-value for Flow Duration: 4.0207770863370624e-163\n",
      "\n",
      "KS Statistic for Total Fwd Packets: 0.13926735728771666\n",
      "P-value for Total Fwd Packets: 2.3883120526414886e-17\n",
      "\n",
      "KS Statistic for Total Backward Packets: 0.2765364551991478\n",
      "P-value for Total Backward Packets: 5.876799803757624e-68\n",
      "\n",
      "KS Statistic for Total Length of Fwd Packets: 0.41210503379755953\n",
      "P-value for Total Length of Fwd Packets: 7.326981011866058e-154\n",
      "\n",
      "KS Statistic for Total Length of Bwd Packets: 0.4338464191472201\n",
      "P-value for Total Length of Bwd Packets: 2.6978906463262607e-171\n",
      "\n",
      "KS Statistic for Fwd Packet Length Max: 0.30510503379755954\n",
      "P-value for Fwd Packet Length Max: 5.97935100462997e-83\n",
      "\n",
      "KS Statistic for Fwd Packet Length Min: 0.35247919245118975\n",
      "P-value for Fwd Packet Length Min: 2.1487001645038962e-111\n",
      "\n",
      "KS Statistic for Fwd Packet Length Mean: 0.3285036509986582\n",
      "P-value for Fwd Packet Length Mean: 1.97583006635276e-96\n",
      "\n",
      "KS Statistic for Fwd Packet Length Std: 0.527619153686835\n",
      "P-value for Fwd Packet Length Std: 1.5038839787286156e-259\n",
      "\n",
      "KS Statistic for Bwd Packet Length Max: 0.5094595534015811\n",
      "P-value for Bwd Packet Length Max: 1.0501692967711644e-240\n",
      "\n",
      "KS Statistic for Bwd Packet Length Min: 0.28684185472528145\n",
      "P-value for Bwd Packet Length Min: 3.504499264078659e-73\n",
      "\n",
      "KS Statistic for Bwd Packet Length Mean: 0.42287558941399006\n",
      "P-value for Bwd Packet Length Mean: 2.30522012434039e-162\n",
      "\n",
      "KS Statistic for Bwd Packet Length Std: 0.5413321789052213\n",
      "P-value for Bwd Packet Length Std: 2.2285219977468241e-274\n",
      "\n",
      "KS Statistic for Flow Bytes/s: 0.5373899859348982\n",
      "P-value for Flow Bytes/s: 4.623807408918112e-270\n",
      "\n",
      "KS Statistic for Flow Packets/s: 0.5658347628961535\n",
      "P-value for Flow Packets/s: 3.24099734397467e-302\n",
      "\n",
      "KS Statistic for Flow IAT Mean: 0.45241503007919925\n",
      "P-value for Flow IAT Mean: 4.751379171089506e-187\n",
      "\n",
      "KS Statistic for Flow IAT Std: 0.4280286619112372\n",
      "P-value for Flow IAT Std: 1.5915361851878945e-166\n",
      "\n",
      "KS Statistic for Flow IAT Max: 0.4265561786752937\n",
      "P-value for Flow IAT Max: 2.4944730341922657e-165\n",
      "\n",
      "KS Statistic for Flow IAT Min: 0.912751949444671\n",
      "P-value for Flow IAT Min: 0.0\n",
      "\n",
      "KS Statistic for Fwd IAT Total: 0.5297920879760444\n",
      "P-value for Fwd IAT Total: 7.283037372315175e-262\n",
      "\n",
      "KS Statistic for Fwd IAT Mean: 0.5530759587351827\n",
      "P-value for Fwd IAT Mean: 1.6779304215738338e-287\n",
      "\n",
      "KS Statistic for Fwd IAT Std: 0.4726173591738414\n",
      "P-value for Fwd IAT Std: 4.0031115130409215e-205\n",
      "\n",
      "KS Statistic for Fwd IAT Max: 0.5282392055283215\n",
      "P-value for Fwd IAT Max: 3.295935460571582e-260\n",
      "\n",
      "KS Statistic for Fwd IAT Min: 0.9220783316597718\n",
      "P-value for Fwd IAT Min: 0.0\n",
      "\n",
      "KS Statistic for Bwd IAT Total: 0.5303854700133106\n",
      "P-value for Bwd IAT Total: 1.690037805903165e-262\n",
      "\n",
      "KS Statistic for Bwd IAT Mean: 0.5966061322406983\n",
      "P-value for Bwd IAT Mean: 0.0\n",
      "\n",
      "KS Statistic for Bwd IAT Std: 0.5412980490284661\n",
      "P-value for Bwd IAT Std: 2.4298542760082075e-274\n",
      "\n",
      "KS Statistic for Bwd IAT Max: 0.5304411556017008\n",
      "P-value for Bwd IAT Max: 1.4733638763804946e-262\n",
      "\n",
      "KS Statistic for Bwd IAT Min: 0.6826682360422276\n",
      "P-value for Bwd IAT Min: 0.0\n",
      "\n",
      "KS Statistic for Fwd PSH Flags: 0.012064013278318408\n",
      "P-value for Fwd PSH Flags: 0.9983391913922213\n",
      "\n",
      "KS Statistic for Bwd PSH Flags: 0.0\n",
      "P-value for Bwd PSH Flags: 1.0\n",
      "\n",
      "KS Statistic for Fwd URG Flags: 0.0\n",
      "P-value for Fwd URG Flags: 1.0\n",
      "\n",
      "KS Statistic for Bwd URG Flags: 0.0\n",
      "P-value for Bwd URG Flags: 1.0\n",
      "\n",
      "KS Statistic for Fwd Header Length: 0.13352941366668042\n",
      "P-value for Fwd Header Length: 5.594278475491238e-16\n",
      "\n",
      "KS Statistic for Bwd Header Length: 0.23682960030321698\n",
      "P-value for Bwd Header Length: 9.939324372287778e-50\n",
      "\n",
      "KS Statistic for Fwd Packets/s: 0.5697686802695182\n",
      "P-value for Fwd Packets/s: 7.510866270665611e-307\n",
      "\n",
      "KS Statistic for Bwd Packets/s: 0.6733115949969193\n",
      "P-value for Bwd Packets/s: 0.0\n",
      "\n",
      "KS Statistic for Min Packet Length: 0.08613842000226335\n",
      "P-value for Min Packet Length: 6.838085915411778e-07\n",
      "\n",
      "KS Statistic for Max Packet Length: 0.4993360445628412\n",
      "P-value for Max Packet Length: 1.3972974499628579e-230\n",
      "\n",
      "KS Statistic for Packet Length Mean: 0.4104309220276021\n",
      "P-value for Packet Length Mean: 1.4555376024533316e-152\n",
      "\n",
      "KS Statistic for Packet Length Std: 0.5123096442050163\n",
      "P-value for Packet Length Std: 1.3253653175422055e-243\n",
      "\n",
      "KS Statistic for Packet Length Variance: 0.5464804013673507\n",
      "P-value for Packet Length Variance: 4.404394253464046e-280\n",
      "\n",
      "KS Statistic for FIN Flag Count: 0.1059157854272611\n",
      "P-value for FIN Flag Count: 3.3386637163633656e-10\n",
      "\n",
      "KS Statistic for SYN Flag Count: 0.012064013278318408\n",
      "P-value for SYN Flag Count: 0.9983391913922213\n",
      "\n",
      "KS Statistic for RST Flag Count: 0.0\n",
      "P-value for RST Flag Count: 1.0\n",
      "\n",
      "KS Statistic for PSH Flag Count: 0.46215984637962837\n",
      "P-value for PSH Flag Count: 1.2074688928515699e-195\n",
      "\n",
      "KS Statistic for ACK Flag Count: 0.4276895959561485\n",
      "P-value for ACK Flag Count: 3.0023715422394957e-166\n",
      "\n",
      "KS Statistic for URG Flag Count: 0.008672581314431382\n",
      "P-value for URG Flag Count: 0.9999988226290255\n",
      "\n",
      "KS Statistic for CWE Flag Count: 0.0\n",
      "P-value for CWE Flag Count: 1.0\n",
      "\n",
      "KS Statistic for ECE Flag Count: 0.0\n",
      "P-value for ECE Flag Count: 1.0\n",
      "\n",
      "KS Statistic for Down/Up Ratio: 0.3788061315221745\n",
      "P-value for Down/Up Ratio: 3.3413928875125064e-129\n",
      "\n",
      "KS Statistic for Average Packet Size: 0.4135891607104044\n",
      "P-value for Average Packet Size: 5.115531896934687e-155\n",
      "\n",
      "KS Statistic for Avg Fwd Segment Size: 0.3285036509986582\n",
      "P-value for Avg Fwd Segment Size: 1.97583006635276e-96\n",
      "\n",
      "KS Statistic for Avg Bwd Segment Size: 0.42287558941399006\n",
      "P-value for Avg Bwd Segment Size: 2.30522012434039e-162\n",
      "\n",
      "KS Statistic for Fwd Header Length.1: 0.13352941366668042\n",
      "P-value for Fwd Header Length.1: 5.594278475491238e-16\n",
      "\n",
      "KS Statistic for Fwd Avg Bytes/Bulk: 0.0\n",
      "P-value for Fwd Avg Bytes/Bulk: 1.0\n",
      "\n",
      "KS Statistic for Fwd Avg Packets/Bulk: 0.0\n",
      "P-value for Fwd Avg Packets/Bulk: 1.0\n",
      "\n",
      "KS Statistic for Fwd Avg Bulk Rate: 0.0\n",
      "P-value for Fwd Avg Bulk Rate: 1.0\n",
      "\n",
      "KS Statistic for Bwd Avg Bytes/Bulk: 0.0\n",
      "P-value for Bwd Avg Bytes/Bulk: 1.0\n",
      "\n",
      "KS Statistic for Bwd Avg Packets/Bulk: 0.0\n",
      "P-value for Bwd Avg Packets/Bulk: 1.0\n",
      "\n",
      "KS Statistic for Bwd Avg Bulk Rate: 0.0\n",
      "P-value for Bwd Avg Bulk Rate: 1.0\n",
      "\n",
      "KS Statistic for Subflow Fwd Packets: 0.13926735728771666\n",
      "P-value for Subflow Fwd Packets: 2.3883120526414886e-17\n",
      "\n",
      "KS Statistic for Subflow Fwd Bytes: 0.41210503379755953\n",
      "P-value for Subflow Fwd Bytes: 7.326981011866058e-154\n",
      "\n",
      "KS Statistic for Subflow Bwd Packets: 0.2765364551991478\n",
      "P-value for Subflow Bwd Packets: 5.876799803757624e-68\n",
      "\n",
      "KS Statistic for Subflow Bwd Bytes: 0.4338464191472201\n",
      "P-value for Subflow Bwd Bytes: 2.6978906463262607e-171\n",
      "\n",
      "KS Statistic for Init_Win_bytes_forward: 0.38103753029026555\n",
      "P-value for Init_Win_bytes_forward: 8.849655695172585e-131\n",
      "\n",
      "KS Statistic for Init_Win_bytes_backward: 0.4830392188210103\n",
      "P-value for Init_Win_bytes_backward: 7.706984830094498e-215\n",
      "\n",
      "KS Statistic for act_data_pkt_fwd: 0.11607634853430138\n",
      "P-value for act_data_pkt_fwd: 3.5889027300234733e-12\n",
      "\n",
      "KS Statistic for min_seg_size_forward: 0.33680134615419155\n",
      "P-value for min_seg_size_forward: 1.7790614764751552e-101\n",
      "\n",
      "KS Statistic for Active Mean: 0.753468139760049\n",
      "P-value for Active Mean: 0.0\n",
      "\n",
      "KS Statistic for Active Std: 0.9961379349987516\n",
      "P-value for Active Std: 0.0\n",
      "\n",
      "KS Statistic for Active Max: 0.7628517308338288\n",
      "P-value for Active Max: 0.0\n",
      "\n",
      "KS Statistic for Active Min: 0.7762665148186536\n",
      "P-value for Active Min: 0.0\n",
      "\n",
      "KS Statistic for Idle Mean: 0.6252826941765449\n",
      "P-value for Idle Mean: 0.0\n",
      "\n",
      "KS Statistic for Idle Std: 0.9638007749278332\n",
      "P-value for Idle Std: 0.0\n",
      "\n",
      "KS Statistic for Idle Max: 0.6252826941765449\n",
      "P-value for Idle Max: 0.0\n",
      "\n",
      "KS Statistic for Idle Min: 0.6252826941765449\n",
      "P-value for Idle Min: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def simple_evaluate_generated_data(data_dir, generated_file_path):\n",
    "    def load_data_from_directory(directory):\n",
    "        all_data = []\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                df = pd.read_csv(file_path)\n",
    "                df.columns = df.columns.str.strip()  #removing spaces from column names\n",
    "                if 'Label' in df.columns:\n",
    "                    df = df[df['Label'] != 'BENIGN'].drop('Label', axis=1)\n",
    "                df = df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "                all_data.append(df)\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    original_data = load_data_from_directory(data_dir)\n",
    "    generated_data = pd.read_csv(generated_file_path)\n",
    "    generated_data.columns = generated_data.columns.str.strip()\n",
    "\n",
    "    #align generated data columns with original data\n",
    "    generated_data = generated_data.reindex(columns=original_data.columns, fill_value=0)\n",
    "\n",
    "    features = original_data.columns\n",
    "\n",
    "    for feature in features:\n",
    "        if feature in original_data.columns:\n",
    "            #KS Test\n",
    "            ks_statistic, p_value = ks_2samp(original_data[feature], generated_data[feature])\n",
    "            print(f\"KS Statistic for {feature}: {ks_statistic}\")\n",
    "            print(f\"P-value for {feature}: {p_value}\\n\")\n",
    "        else:\n",
    "            print(f\"The feature '{feature}' is not found in the dataset.\")\n",
    "\n",
    "data_dir = 'gan_dataset'\n",
    "generated_file_path = 'diffusion_model_results.csv'\n",
    "\n",
    "simple_evaluate_generated_data(data_dir, generated_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
